To be completed:
1) 

Needs checking:
1) Not sure if the arguments for the stft is correct - used the example code to fill in the gaps for now
2) Verify power-law compression - formula (mu-law??)
3) Double check that input audio are indeed mono (by taking the left channel if stereo)
4) Convolution network - padding valid vs same? ; 'Context' in the table in the paper??
5) LSTM settings; Bidirectional merge_mode
6) Reshape tuple ordering correct? (position of num_speakers)
7) Can spectrograms be combined directly (instead of wav files)? Even after power law compression?
8) Include permutation variations when mixing audio to create the dataset?
9) Type for ndarray? float32, float64, ...?
10) Loss function: mse vs model_loss.py
